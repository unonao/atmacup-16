{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6a4872f-e645-4196-aa1e-5778191cd28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "567f430f-170b-4814-ad37-1be05b4bb3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug: true\n",
      "seed: 7\n",
      "dir:\n",
      "  data_dir: /kaggle/working/input/atmaCup16_Dataset\n",
      "  output_dir: /kaggle/working/output\n",
      "  exp_dir: /kaggle/working/output/exp\n",
      "  cand_unsupervised_dir: /kaggle/working/output/cand_unsupervised\n",
      "  cand_supervised_dir: /kaggle/working/output/cand_supervised\n",
      "  datasets_dir: /kaggle/working/output/datasets\n",
      "exp:\n",
      "  fold_path: /kaggle/working/output/datasets/make_cv/base/train_fold.parquet\n",
      "  candidate_info_list:\n",
      "  - name: transition_prob/base\n",
      "    max_num_candidates: 100\n",
      "    dir: /kaggle/working/output/cand_unsupervised/transition_prob/base\n",
      "  - name: transition_prob_all/base\n",
      "    max_num_candidates: 100\n",
      "    dir: /kaggle/working/output/cand_unsupervised/transition_prob_all/base\n",
      "  - name: ranking_location/sml_cd\n",
      "    max_num_candidates: 20\n",
      "    dir: /kaggle/working/output/cand_unsupervised/ranking_location/sml_cd\n",
      "  - name: ranking_location/lrg_cd\n",
      "    max_num_candidates: 20\n",
      "    dir: /kaggle/working/output/cand_unsupervised/ranking_location/lrg_cd\n",
      "  - name: ranking_location/ken_cd\n",
      "    max_num_candidates: 5\n",
      "    dir: /kaggle/working/output/cand_unsupervised/ranking_location/ken_cd\n",
      "  - name: ranking_location/wid_cd\n",
      "    max_num_candidates: 5\n",
      "    dir: /kaggle/working/output/cand_unsupervised/ranking_location/wid_cd\n",
      "  transition_prob_path: /kaggle/working/output/cand_unsupervised/transition_prob/base/yad2yad_feature.parquet\n",
      "  yad_feature_paths:\n",
      "  - output/cand_unsupervised/ranking/base/yad_feature.parquet\n",
      "  - output/cand_unsupervised/ranking_location/ken_cd/yad_feature.parquet\n",
      "  - output/cand_unsupervised/ranking_location/lrg_cd/yad_feature.parquet\n",
      "  - output/cand_unsupervised/ranking_location/sml_cd/yad_feature.parquet\n",
      "  - output/cand_unsupervised/ranking_location/wid_cd/yad_feature.parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../generate_datasets/009\"):\n",
    "    cfg = compose(config_name=\"config.yaml\", overrides=[\"debug=True\"])\n",
    "    print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dfb70b1-f998-432b-b216-790c00ca5955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import hydra\n",
    "import polars as pl\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from utils.data import convert_to_32bit\n",
    "from utils.load import load_label_data, load_log_data, load_yad_data\n",
    "from utils.logger import get_logger\n",
    "\n",
    "numerical_cols = [  # あとで書き換えるので注意\n",
    "    \"total_room_cnt\",\n",
    "    \"wireless_lan_flg\",\n",
    "    \"onsen_flg\",\n",
    "    \"kd_stn_5min\",\n",
    "    \"kd_bch_5min\",\n",
    "    \"kd_slp_5min\",\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    \"yad_type\",\n",
    "    \"wid_cd\",\n",
    "    \"ken_cd\",\n",
    "    \"lrg_cd\",\n",
    "    \"sml_cd\",\n",
    "]\n",
    "\n",
    "logger = None\n",
    "ordinal_encoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05dbb03b-d62e-452b-9bc4-523572756ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yad_data_with_features(cfg):\n",
    "    global numerical_cols\n",
    "    yad_df = load_yad_data(Path(cfg.dir.data_dir))\n",
    "    original_cols = yad_df.columns\n",
    "    for path in cfg.exp.yad_feature_paths:\n",
    "        feature_df = pl.read_parquet(path)\n",
    "        yad_df = yad_df.join(feature_df, on=\"yad_no\")\n",
    "    new_cols = [col for col in yad_df.columns if col not in original_cols]\n",
    "    numerical_cols = list(set(numerical_cols) | set(new_cols))\n",
    "    return yad_df\n",
    "\n",
    "\n",
    "def load_and_union_candidates(cfg, mode: str):\n",
    "    # logデータのsession中のyad_noを候補に加える\n",
    "    log_df = load_log_data(Path(cfg.dir.data_dir), mode)\n",
    "    df = log_df.group_by(\"session_id\").agg(pl.col(\"yad_no\").alias(\"candidates\"))\n",
    "    dfs = [df]\n",
    "    for candidate_info in cfg.exp.candidate_info_list:\n",
    "        df = pl.read_parquet(Path(candidate_info[\"dir\"]) / f\"{mode}_candidate.parquet\")\n",
    "        df = df.with_columns(\n",
    "            pl.col(\"candidates\")\n",
    "            .list.head(candidate_info[\"max_num_candidates\"])\n",
    "            .alias(\"candidates\")\n",
    "        ).filter(pl.col(\"candidates\").list.len() > 0)\n",
    "        dfs.append(df)\n",
    "    df = pl.concat(dfs)\n",
    "    df = (\n",
    "        df.group_by(\"session_id\")\n",
    "        .agg(pl.col(\"candidates\").flatten())\n",
    "        .with_columns(pl.col(\"candidates\").list.unique())\n",
    "    ).select([\"session_id\", \"candidates\"])\n",
    "\n",
    "    # リストを展開\n",
    "    candidate_df = df.explode(\"candidates\")\n",
    "\n",
    "    # セッション最後のyad_noを除外\n",
    "    last_df = (\n",
    "        load_log_data(Path(cfg.dir.data_dir), mode)\n",
    "        .group_by(\"session_id\")\n",
    "        .agg(pl.col(\"yad_no\").last().alias(\"candidates\"))\n",
    "        .with_columns(pl.lit(True).alias(\"last\"))\n",
    "        .sort(by=\"session_id\")\n",
    "    )\n",
    "    candidate_df = (\n",
    "        candidate_df.join(last_df, on=[\"session_id\", \"candidates\"], how=\"left\")\n",
    "        .filter(pl.col(\"last\").is_null())\n",
    "        .drop(\"last\")\n",
    "    )\n",
    "    return candidate_df\n",
    "\n",
    "\n",
    "def concat_label_fold(cfg, mode: str, candidate_df):\n",
    "    \"\"\"\n",
    "    train に対して original, label, fold を付与する\n",
    "    validationのスコア計算時にはoriginalを外して計算を行う\n",
    "    \"\"\"\n",
    "    if mode == \"train\":\n",
    "        candidate_df = (\n",
    "            pl.concat(\n",
    "                [\n",
    "                    candidate_df.with_columns(\n",
    "                        pl.lit(True).alias(\"original\"), pl.lit(False).alias(\"label\")\n",
    "                    ),\n",
    "                    load_label_data(Path(cfg.dir.data_dir))\n",
    "                    .with_columns(\n",
    "                        pl.col(\"yad_no\").alias(\"candidates\"),\n",
    "                        pl.lit(False).alias(\"original\"),\n",
    "                        pl.lit(True).alias(\"label\"),\n",
    "                    )\n",
    "                    .drop(\"yad_no\"),\n",
    "                ]\n",
    "            )\n",
    "            .group_by([\"session_id\", \"candidates\"])\n",
    "            .agg(pl.sum(\"original\"), pl.sum(\"label\"))\n",
    "        )\n",
    "        fold_df = pl.read_parquet(cfg.exp.fold_path)\n",
    "        candidate_df = candidate_df.join(fold_df, on=\"session_id\")\n",
    "    return candidate_df\n",
    "\n",
    "\n",
    "def concat_session_feature(cfg, mode: str, candidate_df: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    # TODO: categorical_colsの情報もあとで追加する\n",
    "    session_id, seq_no, yad_no に yado.csv を結合して集約し、セッションに関する特徴量を作成する\n",
    "    \"\"\"\n",
    "    log_df = load_log_data(Path(cfg.dir.data_dir), mode)\n",
    "    yad_df = load_yad_data_with_features(cfg)\n",
    "    log_yad_df = log_df.join(yad_df.fill_null(0), on=\"yad_no\")\n",
    "    log_yad_df = log_yad_df.group_by(by=\"session_id\").agg(\n",
    "        [pl.sum(col).name.suffix(\"_session_sum\") for col in numerical_cols]\n",
    "        + [pl.min(col).name.suffix(\"_session_min\") for col in numerical_cols]\n",
    "        + [pl.max(col).name.suffix(\"_session_max\") for col in numerical_cols]\n",
    "        + [pl.std(col).name.suffix(\"_session_std\") for col in numerical_cols]\n",
    "    )\n",
    "\n",
    "    candidate_df = candidate_df.join(log_yad_df, on=\"session_id\")\n",
    "\n",
    "    return candidate_df\n",
    "\n",
    "\n",
    "def concat_candidate_feature(cfg, mode: str, candidate_df: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    # TODO: categorical_colsの情報もあとで追加する\n",
    "    candidateの特徴量を抽出する\n",
    "    \"\"\"\n",
    "    original_cols = candidate_df.columns\n",
    "\n",
    "    yad_df = load_yad_data_with_features(cfg)\n",
    "    candidate_yad_df = candidate_df.join(\n",
    "        yad_df.select([\"yad_no\"] + numerical_cols + categorical_cols),\n",
    "        left_on=\"candidates\",\n",
    "        right_on=\"yad_no\",\n",
    "    )\n",
    "\n",
    "    new_cols = [col for col in candidate_yad_df.columns if col not in original_cols]\n",
    "    print(f\"new_cols: {new_cols}\")\n",
    "    return candidate_yad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bf9a3a-382a-4bd5-baef-34311294be09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_cols: ['rank_ranking_location/wid_cd', 'total_room_cnt', 'rank_ranking_location/lrg_cd', 'kd_stn_5min', 'rank_ranking/base', 'onsen_flg', 'rank_ranking_location/sml_cd', 'kd_slp_5min', 'counts_ranking_location/wid_cd', 'rank_ranking_location/ken_cd', 'counts_ranking_location/sml_cd', 'counts_ranking/base', 'wireless_lan_flg', 'kd_bch_5min', 'counts_ranking_location/ken_cd', 'counts_ranking_location/lrg_cd', 'yad_type', 'wid_cd', 'ken_cd', 'lrg_cd', 'sml_cd']\n"
     ]
    }
   ],
   "source": [
    "mode = \"train\"\n",
    "candidate_df = load_and_union_candidates(cfg, mode)\n",
    "\n",
    "candidate_df2 = concat_label_fold(cfg, mode, candidate_df)\n",
    "\n",
    "candidate_df3 = concat_session_feature(cfg, mode, candidate_df2)\n",
    "\n",
    "candidate_df4 = concat_candidate_feature(cfg, mode, candidate_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53dab90-7262-4173-b43a-1be9f21abf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_session_candidate_feature(cfg, mode: str, candidate_df: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    session中の特徴とcandidateの関係性を特徴量として抽出する\n",
    "    例: session中におけるcandidateの出現回数(割合)、candidateと同一地域のものを見た回数(割合)\n",
    "    \"\"\"\n",
    "    original_cols = candidate_df.columns\n",
    "    print(original_cols)\n",
    "\n",
    "    # 同じ candidate の出現回数\n",
    "    log_df = load_log_data(Path(cfg.dir.data_dir), mode)\n",
    "    tmp = (\n",
    "        log_df.group_by(by=[\"session_id\", \"yad_no\"])\n",
    "        .agg(pl.count(\"session_id\").alias(\"appear_count\"))\n",
    "        .with_columns(\n",
    "            (\n",
    "                pl.col(\"appear_count\") / pl.col(\"appear_count\").sum().over(\"session_id\")\n",
    "            ).alias(\"appear_rate\"),\n",
    "            pl.col(\"yad_no\").alias(\"candidates\"),\n",
    "        )\n",
    "    )\n",
    "    candidate_df = candidate_df.join(\n",
    "        tmp.select([\"session_id\", \"candidates\", \"appear_count\", \"appear_rate\"]),\n",
    "        on=[\"session_id\", \"candidates\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # 同じ categorical の出現回数\n",
    "    ## (series_id, categorical) でグループ化して、session_id ごとに出現回数を集計する\n",
    "    log_df = load_log_data(Path(cfg.dir.data_dir), mode)\n",
    "    yad_df = load_yad_data(Path(cfg.dir.data_dir))\n",
    "    log_yad_df = log_df.join(yad_df.fill_null(0), on=\"yad_no\")\n",
    "    for col in categorical_cols:\n",
    "        tmp = (\n",
    "            log_yad_df.group_by(by=[\"session_id\", col])\n",
    "            .agg(pl.count(\"session_id\").alias(f\"same_{col}_count\"))\n",
    "            .with_columns(\n",
    "                pl.col(f\"same_{col}_count\").sum().over(\"session_id\").alias(\"seq_sum\")\n",
    "            )\n",
    "            .with_columns(\n",
    "                (pl.col(f\"same_{col}_count\") / pl.col(\"seq_sum\")).alias(\n",
    "                    f\"same_{col}_rate\"\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        candidate_df = candidate_df.join(\n",
    "            tmp.select([\"session_id\", col, f\"same_{col}_count\", f\"same_{col}_rate\"]),\n",
    "            on=[\"session_id\", col],\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "    # transition probを追加\n",
    "    yad2yad_prob = pl.read_parquet(cfg.exp.transition_prob_path)\n",
    "    log_df = load_log_data(Path(cfg.dir.data_dir), mode)\n",
    "    last_log_df = (\n",
    "        log_df.group_by(\"session_id\")\n",
    "        .agg(pl.all().sort_by(\"seq_no\").last())\n",
    "        .sort(by=\"session_id\")\n",
    "        .with_columns(pl.col(\"yad_no\").alias(\"from_yad_no\"))\n",
    "    ).select([\"session_id\", \"from_yad_no\"])\n",
    "    last_log_prob_df = last_log_df.join(yad2yad_prob, on=\"from_yad_no\")\n",
    "    candidate_df = candidate_df.join(\n",
    "        last_log_prob_df,\n",
    "        left_on=[\"session_id\", \"candidates\"],\n",
    "        right_on=[\"session_id\", \"to_yad_no\"],\n",
    "        how=\"left\",\n",
    "    ).drop(\"from_yad_no\")\n",
    "\n",
    "    # last 以外からのtransition probも追加\n",
    "    yad2yad_prob = pl.read_parquet(cfg.exp.transition_prob_path)\n",
    "    prob_col = \"transition_prob_transition_prob/base\"\n",
    "    log_df = load_log_data(Path(cfg.dir.data_dir), mode)\n",
    "    log_df = (\n",
    "        log_df.sort(by=\"session_id\").with_columns(pl.col(\"yad_no\").alias(\"from_yad_no\"))\n",
    "    ).select([\"session_id\", \"from_yad_no\"])\n",
    "    log_df = (\n",
    "        log_df.join(yad2yad_prob, on=\"from_yad_no\")\n",
    "        .group_by([\"session_id\", \"to_yad_no\"])\n",
    "        .agg(pl.sum(prob_col).alias(prob_col + \"_from_all\"))\n",
    "    )\n",
    "    candidate_df = candidate_df.join(\n",
    "        log_df,\n",
    "        left_on=[\"session_id\", \"candidates\"],\n",
    "        right_on=[\"session_id\", \"to_yad_no\"],\n",
    "        how=\"left\",\n",
    "    ).drop(\"from_yad_no\")\n",
    "\n",
    "    # 増えたカラムを出力\n",
    "    new_cols = [col for col in candidate_df.columns if col not in original_cols]\n",
    "    print(f\"new_cols: {new_cols}\")\n",
    "\n",
    "    return candidate_df\n",
    "\n",
    "\n",
    "concat_session_candidate_feature(cfg, mode, candidate_df4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
